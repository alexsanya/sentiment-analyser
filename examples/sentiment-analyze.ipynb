{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05f0d99f-52fe-411d-aa31-b3576cbf80c7",
   "metadata": {},
   "source": [
    "# Sentiment analyze of tweet content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543b4319-f78b-4cec-9bb0-9947bb5b0940",
   "metadata": {},
   "source": [
    "## Agent to search data in URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7e9cb21-78df-43e5-87ab-f60aae87d359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b95d85e-acfd-4575-91f0-9528bc3f9f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== JUPYTER NOTEBOOK COMPATIBLE FIRECRAWL AGENT =====\n",
    "# Run each cell separately in Jupyter\n",
    "\n",
    "# Cell 1: Imports and Setup\n",
    "import asyncio\n",
    "import re\n",
    "import os\n",
    "from typing import List, Optional, Dict, Any, Union\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "\n",
    "# Import order is important to avoid conflicts\n",
    "from pydantic import BaseModel, field_validator, ValidationError\n",
    "from pydantic import Field as PydanticField  # Alias to avoid conflicts\n",
    "from pydantic import HttpUrl\n",
    "\n",
    "# Then import PydanticAI components\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.mcp import MCPServerSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e792edcd-d930-4f98-bca3-aee78d367605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imports completed successfully\n"
     ]
    }
   ],
   "source": [
    "# For Jupyter environment\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(\"✅ Imports completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64c11b4e-454f-4eaf-aaf6-400e609c35da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import base58\n",
    "from typing import Union\n",
    "\n",
    "def is_valid_solana_address(address: str) -> bool:\n",
    "    \"\"\"\n",
    "    Verify if a string is a valid Solana address (token or otherwise).\n",
    "    \n",
    "    Args:\n",
    "        address (str): The address string to validate\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if valid Solana address, False otherwise\n",
    "    \"\"\"\n",
    "    if not isinstance(address, str):\n",
    "        return False\n",
    "    \n",
    "    # Check length (Solana addresses are typically 32-44 characters)\n",
    "    if len(address) < 32 or len(address) > 44:\n",
    "        return False\n",
    "    \n",
    "    # Check if it contains only valid base58 characters\n",
    "    # Base58 alphabet: 123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz\n",
    "    base58_pattern = r'^[1-9A-HJ-NP-Za-km-z]+$'\n",
    "    if not re.match(base58_pattern, address):\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Attempt to decode the base58 string\n",
    "        decoded = base58.b58decode(address)\n",
    "        \n",
    "        # Solana addresses should decode to exactly 32 bytes\n",
    "        if len(decoded) != 32:\n",
    "            return False\n",
    "            \n",
    "        return True\n",
    "    except Exception:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15d3aa71-ba27-4666-b61f-07a64d5ef1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_evm_address(address: str) -> bool:\n",
    "    \"\"\"\n",
    "    Validates if the given address is a valid EVM blockchain address.\n",
    "    \n",
    "    Args:\n",
    "        address (str): The address string to validate\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if the address is valid, False otherwise\n",
    "        \n",
    "    Examples:\n",
    "        >>> is_valid_evm_address(\"0x742d35Cc6765C0532575f5A2c0a078Df8a2D4e5e\")\n",
    "        True\n",
    "        >>> is_valid_evm_address(\"0xinvalid\")\n",
    "        False\n",
    "        >>> is_valid_evm_address(\"742d35Cc6765C0532575f5A2c0a078Df8a2D4e5e\")\n",
    "        False\n",
    "    \"\"\"\n",
    "    if not isinstance(address, str):\n",
    "        return False\n",
    "    \n",
    "    # EVM address pattern: 0x followed by exactly 40 hexadecimal characters\n",
    "    pattern = r'^0x[a-fA-F0-9]{40}$'\n",
    "    \n",
    "    return bool(re.match(pattern, address))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6562e443-f7b1-44c2-9918-1e7a156dcf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenDetails(BaseModel):\n",
    "    \"\"\"Details of token/coin in blockchain\"\"\"\n",
    "    chain_id: Optional[int] = PydanticField(description = \"Id of blockchain\")\n",
    "    chain_name: Optional[str]\n",
    "    is_release: Optional[bool]\n",
    "    chain_defined_explicitly: Optional[bool] = PydanticField(description = \"Whether name of blockchain been mentioned explicitly in text\")\n",
    "    definition_fragment: Optional[str] = PydanticField(description = \"A fragment of content where name of blockchain been mentioned explicitly\")\n",
    "    token_address: str = PydanticField(description=\"Address of token\")\n",
    "\n",
    "    @field_validator('token_address')\n",
    "    @classmethod\n",
    "    def validate_token(cls, address: str) -> str:\n",
    "        \"\"\"Ensure token address is matching the pattern\"\"\"\n",
    "        if is_valid_solana_address(address) or is_valid_evm_address(address):\n",
    "            return address\n",
    "        raise ValueError(\"Token address should match the pattern\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "933b9eb7-483c-463d-943b-275f2d1b6437",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoTokenFound(BaseModel):\n",
    "    \"\"\"When no token details found\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cf50b41-1aab-49e6-8abc-85363e8951cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelseaseAnnouncementWithoutDetails(BaseModel):\n",
    "    \"\"\"When no token details found but release is announced\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52791b5b-9be8-47aa-9035-25be61c6abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_ids_list = \"\"\"\n",
    "Here's a markdown table with chain IDs and names for the most popular public blockchains:\n",
    "\n",
    "| Chain ID | Chain Name |\n",
    "|----------|------------|\n",
    "| 1 | Ethereum Mainnet |\n",
    "| 56 | BNB Smart Chain (BSC) |\n",
    "| 137 | Polygon |\n",
    "| 43114 | Avalanche C-Chain |\n",
    "| 250 | Fantom Opera |\n",
    "| 42161 | Arbitrum One |\n",
    "| 10 | Optimism |\n",
    "| 25 | Cronos |\n",
    "| 100 | Gnosis Chain (xDai) |\n",
    "| 1284 | Moonbeam |\n",
    "| 1285 | Moonriver |\n",
    "| 42220 | Celo |\n",
    "| 128 | Huobi ECO Chain (HECO) |\n",
    "| 66 | OKExChain |\n",
    "| 321 | KuCoin Community Chain (KCC) |\n",
    "| 1666600000 | Harmony One Shard 0 |\n",
    "| 288 | Boba Network |\n",
    "| 1313161554 | Aurora |\n",
    "| 8217 | Klaytn Cypress |\n",
    "| 82 | Meter |\n",
    "| 1088 | Metis Andromeda |\n",
    "| 199 | BitTorrent Chain |\n",
    "| 324 | zkSync Era |\n",
    "| 5000 | Mantle |\n",
    "| 59144 | Linea |\n",
    "| 534352 | Scroll |\n",
    "| 8453 | Base |\n",
    "\n",
    "These are the most commonly used public blockchains with their respective chain IDs as defined in the EIP-155 standard for Ethereum-compatible networks.\n",
    "\"\"\"\n",
    "\n",
    "contract_address_patterns = \"\"\"\n",
    "| Blockchain Type                    | Address Format | Regex Pattern                   | Description                                      |\n",
    "| ---------------------------------- | -------------- | ------------------------------- | ------------------------------------------------ |\n",
    "| EVM (Ethereum, BSC, Polygon, etc.) | Hexadecimal    | `^0x[a-fA-F0-9]{40}$`           | 20-byte hex string with \"0x\" prefix              |\n",
    "| EVM (Case-insensitive)             | Hexadecimal    | `^0x[a-fA-F0-9]{40}$`           | Standard EVM address format                      |\n",
    "| EVM (Checksummed)                  | Mixed Case     | `^0x[a-fA-F0-9]{40}$`           | EIP-55 checksummed (case matters for validation) |\n",
    "| Solana                             | Base58         | `^[1-9A-HJ-NP-Za-km-z]{32,44}$` | Base58 encoded, 32-44 characters                 |\n",
    "| Solana (Strict)                    | Base58         | `^[1-9A-HJ-NP-Za-km-z]{43,44}$` | More precise length range                        |\n",
    "| Solana (Most Common)               | Base58         | `^[1-9A-HJ-NP-Za-km-z]{44}$`    | Exactly 44 characters (most common)              |\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40db2216-ec56-47a5-a87c-d49c4011f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirecrawlAgent:\n",
    "    \"\"\"\n",
    "    A PydanticAI agent that uses Firecrawl MCP server for web scraping capabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"openai:gpt-4o\"):\n",
    "        \"\"\"\n",
    "        Initialize the agent with Firecrawl MCP server connection.\n",
    "        \n",
    "        Args:\n",
    "            model_name: The LLM model to use (default: gpt-4o)\n",
    "        \"\"\"\n",
    "        # Create MCP server connection to Firecrawl running in SSE mode\n",
    "        self.firecrawl_server = MCPServerSSE(\n",
    "            url='http://localhost:3000/sse',  # Default SSE endpoint for Firecrawl MCP\n",
    "            tool_prefix='firecrawl'  # Optional: prefix tools to avoid naming conflicts\n",
    "        )\n",
    "        \n",
    "        # Initialize the agent with the MCP server\n",
    "        self.agent = Agent[None, TokenDetails | NoTokenFound | RelseaseAnnouncementWithoutDetails](\n",
    "            model=model_name,\n",
    "            output_type=TokenDetails | NoTokenFound | RelseaseAnnouncementWithoutDetails,\n",
    "            retries=4,\n",
    "            system_prompt=(\n",
    "                \"You are a web scraping assistant powered by Firecrawl. \",\n",
    "                \"Your task is to scrape provided webpage and search if it contain an announcement of a new token/coin release.\",\n",
    "                \"Parse the token address and blockchain it deployed to\",\n",
    "                \"If blockchain is not found determine it based on address fromat(EVM/Solana).\",\n",
    "                chain_ids_list,\n",
    "                contract_address_patterns\n",
    "            ),\n",
    "            mcp_servers=[self.firecrawl_server]\n",
    "        )\n",
    "    \n",
    "    async def run(self, url: str) -> TokenDetails | NoTokenFound | RelseaseAnnouncementWithoutDetails:\n",
    "        \"\"\"\n",
    "        Process a user query using the agent with Firecrawl capabilities.\n",
    "        \n",
    "        Args:\n",
    "            url: The url to crawl\n",
    "            \n",
    "        Returns:\n",
    "            The token data if found\n",
    "        \"\"\"\n",
    "        async with self.agent.run_mcp_servers():\n",
    "            result = await self.agent.run(user_query)\n",
    "            return result.output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868d3f14-d099-4dfd-bc82-5a934e9d3416",
   "metadata": {},
   "source": [
    "## Agent to search data in pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2413eb38-19a9-4462-bf0d-5e53b741708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_token_url = \"https://pbs.twimg.com/media/GhivrlDWAAA7Ex3?format=jpg&name=medium\"\n",
    "malania_token_url = \"https://lh7-rt.googleusercontent.com/docsz/AD_4nXcNy9kHtzbuH-N-F9B8zy7oqkUobYkzXWhAKqI4qXP7JSIihBNHhJJfz-1gmvJDnxYiTPHRinIe8wBQ3VMBZU0aGxyb6U8k6SWGU5NleZg2AVGyxI7WuyJGcUJ73oG_THgfF_bX?key=qxx7aSSAQfwoulEynZFGQMDH\"\n",
    "no_announcement_url=\"https://bitcoinworld.co.in/wp-content/uploads/Melania-Trumps-Meme-Coin-MELANIA-B.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b0f349f-c37f-4c03-8b1f-49163bde6d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import ImageUrl\n",
    "\n",
    "class ImageSearchAgent:\n",
    "    \"\"\"\n",
    "    A PydanticAI agent that analizing images and search for new token release announcements \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"openai:gpt-4o\"):\n",
    "        \"\"\"\n",
    "        Initialize the agent\n",
    "        \n",
    "        Args:\n",
    "            model_name: The LLM model to use (default: gpt-4o)\n",
    "        \"\"\"\n",
    "        self.agent = Agent[None, TokenDetails | NoTokenFound | RelseaseAnnouncementWithoutDetails](\n",
    "            model=model_name,\n",
    "            output_type=TokenDetails | NoTokenFound | RelseaseAnnouncementWithoutDetails,\n",
    "            retries=4,\n",
    "            system_prompt=(\n",
    "                \"You are text pattern recognition agent that works with images\",\n",
    "                \"Your task is to scan every text you found in given image and search for announcement of a new token/coin release.\",\n",
    "                \"Parse the token address using Regex Pattern and blockchain it deployed to.\",\n",
    "                \"If blockchain is not found, determine it based on address Regex Pattern (EVM/Solana).\",\n",
    "                chain_ids_list,\n",
    "                contract_address_patterns\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    async def run(self, image_url: str) -> TokenDetails | NoTokenFound | RelseaseAnnouncementWithoutDetails:\n",
    "        \"\"\"\n",
    "        Process a user query\n",
    "        Args:\n",
    "            image_url: The url of an image\n",
    "            \n",
    "        Returns:\n",
    "            The token data if found\n",
    "        \"\"\"\n",
    "        result = await self.agent.run(\n",
    "            [\n",
    "                ImageUrl(url=image_url)\n",
    "            ]\n",
    "        )\n",
    "        return result.output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ce4332-573e-453b-91a1-40daf8a876f1",
   "metadata": {},
   "source": [
    "## Agent to search data in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fab76d3-57e2-4c79-8ccd-1fe80c0c3200",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSearchAgent:\n",
    "    \"\"\"\n",
    "    A PydanticAI agent that analizing text and search for new token release announcements \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"openai:gpt-4o\"):\n",
    "        \"\"\"\n",
    "        Initialize the agent\n",
    "        \n",
    "        Args:\n",
    "            model_name: The LLM model to use (default: gpt-4o)\n",
    "        \"\"\"\n",
    "        self.agent = Agent[None, TokenDetails | NoTokenFound | RelseaseAnnouncementWithoutDetails](\n",
    "            model=model_name,\n",
    "            output_type=TokenDetails | NoTokenFound | RelseaseAnnouncementWithoutDetails,\n",
    "            retries=4,\n",
    "            system_prompt=(\n",
    "                \"Your task is scan given text and search for announcement of a new token/coin release.\",\n",
    "                \"Parse the token address using Regex Pattern and blockchain it deployed to.\",\n",
    "                \"If blockchain is not found, determine it based on address Regex Pattern (EVM/Solana).\",\n",
    "                chain_ids_list,\n",
    "                contract_address_patterns\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    async def run(self, text: str) -> TokenDetails | NoTokenFound | RelseaseAnnouncementWithoutDetails:\n",
    "        \"\"\"\n",
    "        Process a user query\n",
    "        Args:\n",
    "            text: The given text\n",
    "            \n",
    "        Returns:\n",
    "            The token data if found\n",
    "        \"\"\"\n",
    "        result = await self.agent.run(text)\n",
    "        return result.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34a6a4d-608f-412f-9350-d1b4b9f2eca3",
   "metadata": {},
   "source": [
    "## Test agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3233df7-5edd-4184-aba7-63c195a5b521",
   "metadata": {},
   "source": [
    "### Firecrawl agen test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f57f0e-e2c3-4575-99c5-1a0b9abef645",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = FirecrawlAgent()\n",
    "await agent.run(\"https://flockerz.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e82fe4e-dafc-4ab3-ae10-3f5cffb00542",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = FirecrawlAgent()\n",
    "await agent.run(\"https://gettrumpmemes.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e34753-9ade-4062-9092-3b63e79fea18",
   "metadata": {},
   "source": [
    "### ImageSearchAgent agent test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11f4c4ff-63c3-4ad2-bb7e-a12edf272204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenDetails(chain_id=None, chain_name=None, is_release=True, chain_defined_explicitly=False, definition_fragment=None, token_address='FUAfBo2jgks6gB4Z4LfZkqSZgzNucisEHqnNebaRxM1P')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = ImageSearchAgent()\n",
    "await agent.run(malania_token_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e6716d-fbee-4d44-9282-08fe505c2dfa",
   "metadata": {},
   "source": [
    "### TextSearchAgent test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34aed09c-8d57-4796-9081-49dc44a91a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_samples = [\n",
    "    'My new token on Polygon blockchain: 0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48. Buy it now!', #explicit chain info, Polygon\n",
    "    'My new token is live: 0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48. Happpy trading!', #no chain info, EVM\n",
    "    'My new token is live on Solana Blockchain: Es9vMFrzaCERmJfrF4H2FYD4KCoNkY11McCe8BenwNYB. Buy now!', #Explicit chain info: Solana\n",
    "    'My new token is live: Es9vMFrzaCERmJfrF4H2FYD4KCoNkY11McCe8BenwNYB. Buy now!', #No chain info: Solana\n",
    "    'Join my webinar tomorrow!', #no announcement\n",
    "    'Just bought a bad of Trump coin (6p6xgHyF7AeE6TZkSmFsko444wqoP15icUSqi2jfGiPN)', #no announcement, Solana address\n",
    "    'Just bought a bad of Trump coin on solana: (6p6xgHyF7AeE6TZkSmFsko444wqoP15icUSqi2jfGiPN)', #no announcement. Solana address\n",
    "    'Just bought a bad of Trump coin on solana: (6p6xgHyF7AeE6TZkSmFsko444wqoP15icUSqi2jfGiPN)', #no announcement. Solana address\n",
    "    'Accumulationg Bonk: 0x1151CB3d861920e07a38e03eEAd12C32178567F6', #no announcement. EVM address\n",
    "    'Accumulationg Bonk on ETH mainnet: 0x1151CB3d861920e07a38e03eEAd12C32178567F6', #no announcement. Eth mainnet\n",
    "    'My new token just released - follow the link to buy!' #release announcement, no token data\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fbd8d90-d606-4e09-beb4-3a3673d9affd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenDetails(chain_id=137, chain_name='Polygon', is_release=True, chain_defined_explicitly=True, definition_fragment='new token on Polygon blockchain', token_address='0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = TextSearchAgent()\n",
    "await agent.run(text_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3735858-ed52-454d-9506-e4cd801ff5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'test_case': 'My new token on Polygon blockchain: 0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48. Buy it now!',\n",
       "  'result': TokenDetails(chain_id=137, chain_name='Polygon', is_release=True, chain_defined_explicitly=True, definition_fragment='My new token on Polygon blockchain:', token_address='0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48'),\n",
       "  'success': True,\n",
       "  'error': None},\n",
       " {'test_case': 'My new token is live: 0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48. Happpy trading!',\n",
       "  'result': TokenDetails(chain_id=1, chain_name='Ethereum Mainnet', is_release=True, chain_defined_explicitly=False, definition_fragment=None, token_address='0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48'),\n",
       "  'success': True,\n",
       "  'error': None},\n",
       " {'test_case': 'My new token is live on Solana Blockchain: Es9vMFrzaCERmJfrF4H2FYD4KCoNkY11McCe8BenwNYB. Buy now!',\n",
       "  'result': TokenDetails(chain_id=None, chain_name='Solana', is_release=True, chain_defined_explicitly=True, definition_fragment='Solana Blockchain', token_address='Es9vMFrzaCERmJfrF4H2FYD4KCoNkY11McCe8BenwNYB'),\n",
       "  'success': True,\n",
       "  'error': None},\n",
       " {'test_case': 'My new token is live: Es9vMFrzaCERmJfrF4H2FYD4KCoNkY11McCe8BenwNYB. Buy now!',\n",
       "  'result': TokenDetails(chain_id=None, chain_name='Solana', is_release=True, chain_defined_explicitly=False, definition_fragment=None, token_address='Es9vMFrzaCERmJfrF4H2FYD4KCoNkY11McCe8BenwNYB'),\n",
       "  'success': True,\n",
       "  'error': None},\n",
       " {'test_case': 'Join my webinar tomorrow!',\n",
       "  'result': NoTokenFound(),\n",
       "  'success': True,\n",
       "  'error': None},\n",
       " {'test_case': 'Just bought a bad of Trump coin (6p6xgHyF7AeE6TZkSmFsko444wqoP15icUSqi2jfGiPN)',\n",
       "  'result': TokenDetails(chain_id=None, chain_name='Solana', is_release=False, chain_defined_explicitly=False, definition_fragment=None, token_address='6p6xgHyF7AeE6TZkSmFsko444wqoP15icUSqi2jfGiPN'),\n",
       "  'success': True,\n",
       "  'error': None},\n",
       " {'test_case': 'Just bought a bad of Trump coin on solana: (6p6xgHyF7AeE6TZkSmFsko444wqoP15icUSqi2jfGiPN)',\n",
       "  'result': TokenDetails(chain_id=None, chain_name='Solana', is_release=None, chain_defined_explicitly=True, definition_fragment='Just bought a bad of Trump coin on solana', token_address='6p6xgHyF7AeE6TZkSmFsko444wqoP15icUSqi2jfGiPN'),\n",
       "  'success': True,\n",
       "  'error': None},\n",
       " {'test_case': 'Just bought a bad of Trump coin on solana: (6p6xgHyF7AeE6TZkSmFsko444wqoP15icUSqi2jfGiPN)',\n",
       "  'result': TokenDetails(chain_id=None, chain_name='Solana', is_release=True, chain_defined_explicitly=True, definition_fragment='on solana', token_address='6p6xgHyF7AeE6TZkSmFsko444wqoP15icUSqi2jfGiPN'),\n",
       "  'success': True,\n",
       "  'error': None},\n",
       " {'test_case': 'Accumulationg Bonk: 0x1151CB3d861920e07a38e03eEAd12C32178567F6',\n",
       "  'result': TokenDetails(chain_id=1, chain_name='Ethereum Mainnet', is_release=False, chain_defined_explicitly=False, definition_fragment=None, token_address='0x1151CB3d861920e07a38e03eEAd12C32178567F6'),\n",
       "  'success': True,\n",
       "  'error': None},\n",
       " {'test_case': 'Accumulationg Bonk on ETH mainnet: 0x1151CB3d861920e07a38e03eEAd12C32178567F6',\n",
       "  'result': TokenDetails(chain_id=1, chain_name='Ethereum Mainnet', is_release=True, chain_defined_explicitly=True, definition_fragment='Accumulating Bonk on ETH mainnet', token_address='0x1151CB3d861920e07a38e03eEAd12C32178567F6'),\n",
       "  'success': True,\n",
       "  'error': None},\n",
       " {'test_case': 'My new token just released - follow the link to buy!',\n",
       "  'result': RelseaseAnnouncementWithoutDetails(),\n",
       "  'success': True,\n",
       "  'error': None}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "max_concurrent = 5\n",
    "# Semaphore to limit concurrent requests\n",
    "semaphore = asyncio.Semaphore(max_concurrent)\n",
    "agent = TextSearchAgent()\n",
    "\n",
    "async def process_single_case_with_limit(test_case: str, index: int):\n",
    "    \"\"\"Process a single test case with concurrency limit\"\"\"\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            result = await agent.run(test_case)\n",
    "            return {\n",
    "                'test_case': test_case,\n",
    "                'result': result,\n",
    "                'success': True,\n",
    "                'error': None\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'index': index,\n",
    "                'test_case': test_case,\n",
    "                'result': None,\n",
    "                'success': False,\n",
    "                'error': str(e)\n",
    "            }\n",
    "\n",
    "\n",
    "tasks = [\n",
    "    process_single_case_with_limit(test_case, index) \n",
    "    for index, test_case in enumerate(text_samples)\n",
    "]\n",
    "await asyncio.gather(*tasks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
